{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Private Aggregation of Teacher Ensembles (PATE)\n",
    "\n",
    "\n",
    "\n",
    "![PATE chart](img/pate.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the [Data](http://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "\n",
    "Downloading may take a few moments, and you should see your progress as the data is loading. You may also choose to change the `batch_size` if you want to load more data at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 32\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False,\n",
    "                                  download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for returning dataloaders for a specified number of teachers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of teachers to essemble\n",
    "num_teachers = 100\n",
    "\n",
    "def get_data_loaders(train_data, num_teachers = 10):\n",
    "    teacher_loaders = []\n",
    "    data_size = len(train_data) // num_teachers\n",
    "\n",
    "    for i in range(num_teachers):\n",
    "        indices = list(range(i*data_size, (i+1) *data_size))\n",
    "        subset_data = Subset(train_data, indices)\n",
    "        loader = torch.utils.data.DataLoader(subset_data, batch_size=batch_size, num_workers=num_workers)\n",
    "        teacher_loaders.append(loader)\n",
    "\n",
    "    return teacher_loaders\n",
    "\n",
    "teacher_loaders = get_data_loaders(train_data, num_teachers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a train student set of 9000 examples and 1000 test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_train_data = Subset(test_data, list(range(9000)))\n",
    "student_test_data = Subset(test_data, list(range(9000, 10000)))\n",
    "\n",
    "student_train_loader = torch.utils.data.DataLoader(student_train_data, batch_size=batch_size, \n",
    "            num_workers=num_workers)\n",
    "student_test_loader = torch.utils.data.DataLoader(student_test_data, batch_size=batch_size, \n",
    "            num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining models\n",
    "\n",
    "I'm going to define a single model for all the teachers, the analysis does not depends on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, epochs=10, print_every=120):\n",
    "    model.to(device)\n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    for e in range(epochs):\n",
    "        # Model in training mode, dropout is on\n",
    "        model.train()\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            steps += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model.forward(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "    outputs = torch.zeros(0, dtype=torch.long).to(device)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        output = model.forward(images)\n",
    "        ps = torch.argmax(torch.exp(output), dim=1)\n",
    "        outputs = torch.cat((outputs, ps))\n",
    "    \n",
    "    return outputs    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training all the teacher models\n",
    "\n",
    "Here we define and train the teachers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training teacher 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training teacher 2\n",
      "Training teacher 3\n",
      "Training teacher 4\n",
      "Training teacher 5\n",
      "Training teacher 6\n",
      "Training teacher 7\n",
      "Training teacher 8\n",
      "Training teacher 9\n",
      "Training teacher 10\n",
      "Training teacher 11\n",
      "Training teacher 12\n",
      "Training teacher 13\n",
      "Training teacher 14\n",
      "Training teacher 15\n",
      "Training teacher 16\n",
      "Training teacher 17\n",
      "Training teacher 18\n",
      "Training teacher 19\n",
      "Training teacher 20\n",
      "Training teacher 21\n",
      "Training teacher 22\n",
      "Training teacher 23\n",
      "Training teacher 24\n",
      "Training teacher 25\n",
      "Training teacher 26\n",
      "Training teacher 27\n",
      "Training teacher 28\n",
      "Training teacher 29\n",
      "Training teacher 30\n",
      "Training teacher 31\n",
      "Training teacher 32\n",
      "Training teacher 33\n",
      "Training teacher 34\n",
      "Training teacher 35\n",
      "Training teacher 36\n",
      "Training teacher 37\n",
      "Training teacher 38\n",
      "Training teacher 39\n",
      "Training teacher 40\n",
      "Training teacher 41\n",
      "Training teacher 42\n",
      "Training teacher 43\n",
      "Training teacher 44\n",
      "Training teacher 45\n",
      "Training teacher 46\n",
      "Training teacher 47\n",
      "Training teacher 48\n",
      "Training teacher 49\n",
      "Training teacher 50\n",
      "Training teacher 51\n",
      "Training teacher 52\n",
      "Training teacher 53\n",
      "Training teacher 54\n",
      "Training teacher 55\n",
      "Training teacher 56\n",
      "Training teacher 57\n",
      "Training teacher 58\n",
      "Training teacher 59\n",
      "Training teacher 60\n",
      "Training teacher 61\n",
      "Training teacher 62\n",
      "Training teacher 63\n",
      "Training teacher 64\n",
      "Training teacher 65\n",
      "Training teacher 66\n",
      "Training teacher 67\n",
      "Training teacher 68\n",
      "Training teacher 69\n",
      "Training teacher 70\n",
      "Training teacher 71\n",
      "Training teacher 72\n",
      "Training teacher 73\n",
      "Training teacher 74\n",
      "Training teacher 75\n",
      "Training teacher 76\n",
      "Training teacher 77\n",
      "Training teacher 78\n",
      "Training teacher 79\n",
      "Training teacher 80\n",
      "Training teacher 81\n",
      "Training teacher 82\n",
      "Training teacher 83\n",
      "Training teacher 84\n",
      "Training teacher 85\n",
      "Training teacher 86\n",
      "Training teacher 87\n",
      "Training teacher 88\n",
      "Training teacher 89\n",
      "Training teacher 90\n",
      "Training teacher 91\n",
      "Training teacher 92\n",
      "Training teacher 93\n",
      "Training teacher 94\n",
      "Training teacher 95\n",
      "Training teacher 96\n",
      "Training teacher 97\n",
      "Training teacher 98\n",
      "Training teacher 99\n",
      "Training teacher 100\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and train the models for each teacher\n",
    "def train_models(num_teachers):\n",
    "    models = []\n",
    "    for t in range(num_teachers):\n",
    "        print(\"Training teacher {}\".format(t+1))\n",
    "        model = Net()\n",
    "        criterion = nn.NLLLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "        train(model, teacher_loaders[t], criterion, optimizer)\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "models = train_models(num_teachers) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated teacher\n",
    "\n",
    "This function predict the labels from all the dataset in each of the teachers, then return all the predictions and the maximum votation after adding laplacian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define epsilon\n",
    "epsilon = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregated teacher\n",
    "\n",
    "This function makes the predictions in all the teachers, count the votes and add noise, then returns the votation and the argmax results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregated_teacher(models, data_loader, epsilon):\n",
    "    preds = torch.torch.zeros((len(models), 9000), dtype=torch.long)\n",
    "    for i, model in enumerate(models):\n",
    "        results = predict(model, data_loader)\n",
    "        preds[i] = results\n",
    "        \n",
    "    labels = np.array([]).astype(int)\n",
    "    for image_preds in np.transpose(preds):\n",
    "        label_counts = np.bincount(image_preds, minlength=10)\n",
    "        beta = 1 / epsilon\n",
    "\n",
    "        for i in range(len(label_counts)):\n",
    "            label_counts[i] += np.random.laplace(0, beta, 1)\n",
    "\n",
    "        new_label = np.argmax(label_counts)\n",
    "        labels = np.append(labels, new_label)\n",
    "    \n",
    "    return preds.numpy(), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "teacher_models = models\n",
    "preds, student_labels = aggregated_teacher(teacher_models, student_train_loader, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATE Analysis\n",
    "\n",
    "Perform PATE analysis and show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Independent Epsilon: 1451.5129254649705\n",
      "Data Dependent Epsilon: 15.661427783915407\n"
     ]
    }
   ],
   "source": [
    "from syft.frameworks.torch.differential_privacy import pate\n",
    "\n",
    "data_dep_eps, data_ind_eps = pate.perform_analysis(teacher_preds=preds, indices=student_labels, noise_eps=epsilon, delta=1e-5)\n",
    "print(\"Data Independent Epsilon:\", data_ind_eps)\n",
    "print(\"Data Dependent Epsilon:\", data_dep_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the student\n",
    "\n",
    "Now we will train the student with the aggregated teacher labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_loader(student_train_loader, labels):\n",
    "    for i, (data, _) in enumerate(iter(student_train_loader)):\n",
    "        yield data, torch.from_numpy(labels[i*len(data):(i+1)*len(data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10..  Training Loss: 0.392..  Test Loss: 1.955..  Test Accuracy: 0.487\n",
      "Epoch: 1/10..  Training Loss: 0.287..  Test Loss: 1.063..  Test Accuracy: 0.719\n",
      "Epoch: 1/10..  Training Loss: 0.196..  Test Loss: 0.700..  Test Accuracy: 0.784\n",
      "Epoch: 1/10..  Training Loss: 0.127..  Test Loss: 0.570..  Test Accuracy: 0.836\n",
      "Epoch: 1/10..  Training Loss: 0.110..  Test Loss: 0.376..  Test Accuracy: 0.890\n",
      "Epoch: 2/10..  Training Loss: 0.121..  Test Loss: 0.380..  Test Accuracy: 0.902\n",
      "Epoch: 2/10..  Training Loss: 0.097..  Test Loss: 0.316..  Test Accuracy: 0.904\n",
      "Epoch: 2/10..  Training Loss: 0.087..  Test Loss: 0.317..  Test Accuracy: 0.899\n",
      "Epoch: 2/10..  Training Loss: 0.081..  Test Loss: 0.292..  Test Accuracy: 0.908\n"
     ]
    }
   ],
   "source": [
    "student_model = Net()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "student_model.to(device)\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "for e in range(epochs):\n",
    "    # Model in training mode, dropout is on\n",
    "    student_model.train()\n",
    "    train_loader = student_loader(student_train_loader, student_labels)\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        steps += 1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = student_model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if steps % 50 == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            student_model.eval()\n",
    "            with torch.no_grad():\n",
    "                for images, labels in student_test_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    log_ps = student_model(images)\n",
    "                    test_loss += criterion(log_ps, labels).item()\n",
    "                    \n",
    "                    # Accuracy\n",
    "                    ps = torch.exp(log_ps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "            student_model.train()\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(student_train_loader)),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(student_test_loader)),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(student_test_loader)))\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 15.074..  Test Accuracy: 27.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "t1_model = models[99]\n",
    "t1_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    for images, labels in student_test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        log_ps = t1_model(images)\n",
    "        test_loss += criterion(log_ps, labels).item()\n",
    "\n",
    "        # Accuracy\n",
    "        ps = torch.exp(log_ps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "    t1_model.train()\n",
    "    print(\"Test Loss: {:.3f}.. \".format(test_loss),\n",
    "          \"Test Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
